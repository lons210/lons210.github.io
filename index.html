Good question. 
Say. 
OK. 
The use of computers to. 
Utilize data and make decisions. 
It. 
One of the one of the key things that's discussed with artificial intelligence ethics is you know how the. 
Data that's used to. 
Train the the algorithm is chosen and that it's kind of representative of the situation and I think that the challenging thing with with AI ethics is that. 
You know you you have. 
People with different different ethics. 
And then you have different people programming the the algorithms and they're. 
Probably have some of those. 
Their personal ethics leak into the into the algorithm and. 
And sometimes it's it's it's probably not a conscious decision either. 
So I think there's a lot of a lot of things to consider, I guess. 

 
Sure. 
I I you think one of the. 
I think the detrimental side is if it starts to take away the. 
Need for people to to to think for themselves, and if it, if it starts to do that, I think that I think that'll be very detrimental to to society. 

 
But I think you know where the most benefits. 
I guess maybe I'm I'm biased, but I think in in healthcare there's there's a lot of strong strong applications for it that can, you know, help people, quality of lives or extend people's lives. 
So I think a lot in healthcare. 

 
I guess yeah. 
One of the things in the in the news recently has been, you know, companies using chat, GPT and and then losing their or or putting their proprietary information into their and kind of making that public, or at least to the algorithm designers they can. 
They can see all that. 
So I think you know if you take away the trade secret, intellectual property aspect of it and assume that the algorithm is running, so inside the company, I think I think it would depend and I guess the the quality of the, the training. 
And so if it's been trained on, you know, let's say it's it's, you know, my team is software developers. 
And so if it's been trained on high quality code and this is how we want it to look, I I could see there be being value in using it like you're saying in in advisory sort of way so. 
I'm not a I'm not aware of. 
I'm not aware of any in my team. 

 
No, I think I think to me right now it's more the. 
Intellectual property aspect and. 
So yeah, right. 
Right now, if we were to put anything in there, I think we would, we would lose control of that. 
So we don't, we're we're holding off to, you know, see if and maybe we end up with a a private instance of it or or something like that. So. 

 
Gabrielse, Bradley (GE HealthCare)   7:39 
I hope I hope not. 
Right now the guidance is to is to is to wait. 

 
Yeah, so, so hopefully not. 

 
It's good question. 
I know there's a a group of people that are kind of doing the evaluation and and I'm not sure what their criteria. 
Uh would, is, or or or would be certainly on the intellectual property, but. 
From potentially on the ethical side as well. 
Sure. 
Can can you say the question one more time? 

 
Mm-hmm. 

 
Sure. 
Yeah. 
I think from the from the ethical side 11 aspect that I would be interested in is, you know on on how the. 
Data was trained and how that data was acquired and whether it you know, the whether the originators of that data are 

 
Supportive of using it in in that way, I think that would be one one aspect to try. 
I would. 
I would say that you know the. 
The quality of the results I think would still be a question mark. 
A lot of what I've been reading is that, you know the accuracy is impressive but not perfect. 
And so for the software that we're writing it, it can't be can't be wrong. 
And so I think that I would be nervous if someone just kind of took the results and said, OK, good, good to go. 
And so I think we would. 
Make sure we would want to, you know, follow our complete process around our our quality process. 
So I think I think I wouldn't just kind of let it let it be used without. 
You know, we we make sure we have code reviews, we make sure we, you know, write tests for it and that sort of thing. 

 
Yep. 

 
Yep. 
Yeah, I think so. 
So I think I mean. 
Think. 
Our probably 2 two types of things I'm kind of thinking about 1 using using it as a tool for my team to develop the products that we're working on. 

 
And then the second, the second part would be that, you know, writing, writing an AI based application that you know that we sell to our our customers. 
We're where they it's the product itself. 

 
Umm, I think I'm from the from the tool standpoint, UM. 
It's it's maybe a little bit easier for me to think about. 
Think about the that because you know we do have all the. 
Umm. 
Due diligence that that we could do and confirm that and and make sure the result is generating our what we'd expect and and that sort of thing and the product side it's it's probably a little bit trickier because then you know once it's out out of our hands and and say running at a hospital and then you don't, you don't really have is good enough of an idea of and you don't have the opportunity to do that due diligence and then it's kind of into the hands of the clinicians to umm make sure that whatever results it's it's generating is is correct. 
So that that's where it's I think meat for me a little bit harder. 

 
I think that's tough, tough question, because there's gonna be. 
I mean, you could, you could compare the results to. 
You know the non AI algorithms that are generated today and and those Nanda algorithms have a accuracy and the AI algorithm could be more accurate. 
But I'm still probably not correct 100% of the time and so I think right, right now. 
You with possibility. 
With the person using it to make sure that it's it's correct, and I think as the algorithms get more and more accurate, they actually run into a problem where the users trust it more and more and maybe are less and less critically. 
Thinking about the results where you have something that works 80% of the time, you know it's gonna be. 
It's gonna be looked at critically every time, because one in five are not gonna be correct and it has to be fixed. 
But if you start to get to, you know, I don't know what the number would be 9590, eight, 99% accuracy then your your maybe lulled into a false sense of security and you you you may not pay as close attention and so then I think it's no even though you know the responsibility may may seem to be on the same person you know reviewing the results of the algorithm the likelihood that they're gonna notice something wrong. 
I think actually goes goes down. 
They don't. 

 
I don't. I don't. 
I don't know. 
I mean, we do have. 
Umm some frameworks? 
I think that are being adopted and I'm I'm not sure if see if attics are included in that or or not. 
I haven't gone through the process. 

 
Yeah, because we're because we're not using it yet. 
I don't. 
I'm not aware of any anything like that. 
Yeah. 
So I don't, I don't know. 
Hmm hmm. 
I I think were. 
Often, often looking at the the accuracy of the the algorithms and whether it's whether it's AI or not. 
So I think that's probably one of the the key things that we're we're looking at. 
You know, we try to have. 
Uh. 
In diverse set of training data, making sure that it's representative of populations. 
So from that standpoint, I think we're, we're considering that, I guess that that aspect of it. 

 
